{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "This exam assesses the candidate's ability to implement and apply Graph Neural Networks (GNNs) for the task of link prediction using PyTorch and `torch_geometric`. The dataset to be used is the MovieLens 100K dataset. Candidates will demonstrate their understanding of GNN concepts, dataset preparation, model implementation, training, and evaluation specific to link prediction tasks.\n",
        "\n",
        "### Exam Components\n",
        "\n",
        "#### 1. Environment Setup\n",
        "- **Objective:** Ensure the Python environment is prepared for working with GNNs, focusing on `torch_geometric`.\n",
        "- **Tasks:**\n",
        "    1. Install `torch_geometric` and any other required libraries.\n",
        "    2. Successfully import the libraries in the notebook."
      ],
      "metadata": {
        "id": "AzzzAggjrzvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyUaHzVHCyqe",
        "outputId": "1e49caf8-ebfa-49fb-dde7-63ac3ba2039f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjrula6411mr"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import torch\n",
        "import string\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "params = {'legend.fontsize': 'medium',\n",
        "          'figure.figsize': (10, 8),\n",
        "          'figure.dpi': 100,\n",
        "         'axes.labelsize': 'medium',\n",
        "         'axes.titlesize':'medium',\n",
        "         'xtick.labelsize':'medium',\n",
        "         'ytick.labelsize':'medium'}\n",
        "plt.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHotZoSa3Q2C",
        "outputId": "97c90de5-62cc-4d17-e337-38112a47d8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.3.0+cu121.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/nightly/torch-2.3.0%2Bcu121/pyg_lib-0.4.0.dev20240710%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.4.0.dev20240710+pt23cu121\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-vsmutimq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-vsmutimq\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit fbafbc4fc9181e8759ec1f39d9618992793b5fe1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.25.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (4.66.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.6.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2024.6.2)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.6.0-py3-none-any.whl size=1122975 sha256=abc5a11943a4f02f8f198ffd45c048f1d91bb6c15260ee474055a3f78589db9d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lldvfowp/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "  Attempting uninstall: torch-geometric\n",
            "    Found existing installation: torch_geometric 2.5.3\n",
            "    Uninstalling torch_geometric-2.5.3:\n",
            "      Successfully uninstalled torch_geometric-2.5.3\n",
            "Successfully installed torch-geometric-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Dataset Preparation\n",
        "- **Objective:** Prepare the MovieLens 100K dataset for a link prediction task.\n",
        "- **Tasks:**\n",
        "    1. Download the MovieLens 100K dataset.\n",
        "    2. Load the dataset and preprocess it to construct a graph where nodes represent movies and users, and edges represent ratings. Edge features can include the rating value."
      ],
      "metadata": {
        "id": "gXvrwMjnr93X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjg00vX1xKBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb161c2d-6cfc-4c95-b68b-d274a9f73e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-10 08:58:12--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  2.69MB/s    in 0.3s    \n",
            "\n",
            "2024-07-10 08:58:13 (2.69 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ],
      "source": [
        "# Download and unzip the dataset\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip -o ml-latest-small.zip\n",
        "\n",
        "movies_path = './ml-latest-small/movies.csv'\n",
        "ratings_path = './ml-latest-small/ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y38GE2qYCKg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831b54c2-05d0-4cf3-b0e1-403c3ba66189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating\n",
            "0       1        1     4.0\n",
            "1       1        3     4.0\n",
            "2       1        6     4.0\n",
            "3       1       47     5.0\n",
            "4       1       50     5.0\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ],
      "source": [
        "# Load the ratings and the movies file\n",
        "ratings_df = pd.read_csv(\n",
        "    ratings_path, usecols=['userId', 'movieId', 'rating']\n",
        ")\n",
        "print(ratings_df.head())\n",
        "\n",
        "movies_df  = pd.read_csv(\n",
        "    movies_path, usecols=['movieId', 'title', 'genres']\n",
        ")\n",
        "print(movies_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nofGiWHv1veF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "55629871-3b11-458a-bb88-7110691ce478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='rating', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(x='rating', data=ratings_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Dataset Preparation\n",
        "- **Objective:** Prepare the MovieLens 100K dataset for a link prediction task.\n",
        "- **Tasks:**\n",
        "    3. Utilize the `torch_geometric.data.Data` class to structure the graph data for processing by your GNN model. This includes:\n",
        "        - Creating a `Data` object that encapsulates the graph's nodes, edges, and any associated features.\n",
        "        - Defining the `edge_index` tensor to represent the graph's connectivity. This tensor indexes nodes and defines which nodes are connected by edges.\n",
        "        - Optionally including node features (such as user or movie attributes) and edge features (such as ratings) to potentially enhance model performance.\n",
        "        - Note: Unlike traditional supervised learning tasks, you will train the model in a transductive manner where the model learns to predict links directly on the entire graph. This approach reflects the real-world application of link prediction, where the model makes predictions on the same graph it was trained on.\n"
      ],
      "metadata": {
        "id": "jaC0-naps12U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split genres and convert into indicator variables:\n",
        "genres = movies_df['genres'].str.get_dummies('|')\n",
        "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
        "# Use genres as movie input features:\n",
        "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
        "assert movie_feat.size() == (9742, 20)  # 9742 movies and 20 genres in total."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAH9p0ri33Ug",
        "outputId": "c52302ad-7e50-450b-8d33-a4d0484fe860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Action  Adventure  Drama  Horror\n",
            "0       0          1      0       0\n",
            "1       0          1      0       0\n",
            "2       0          0      0       0\n",
            "3       0          0      1       0\n",
            "4       0          0      0       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
        "unique_user_id = ratings_df['userId'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userId': unique_user_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
        "})\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "\n",
        "\n",
        "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
        "unique_movie_id = ratings_df['movieId'].unique()\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'movieId': unique_movie_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_movie_id)),\n",
        "})\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "# Perform merge to obtain the edges from users and movies:\n",
        "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
        "                            left_on='userId', right_on='userId', how='left')\n",
        "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
        "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
        "                            left_on='movieId', right_on='movieId', how='left')\n",
        "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
        "# With this, we are ready to construct our `edge_index` in COO format\n",
        "# following PyG semantics:\n",
        "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
        "assert edge_index_user_to_movie.size() == (2, 100836)\n",
        "\n",
        "print()\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"=================================================\")\n",
        "print(edge_index_user_to_movie)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DnmkhJ_35SC",
        "outputId": "916e272b-2fdf-4f65-952e-d17eb14f40a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   userId  mappedID\n",
            "0       1         0\n",
            "1       2         1\n",
            "2       3         2\n",
            "3       4         3\n",
            "4       5         4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   movieId  mappedID\n",
            "0        1         0\n",
            "1        3         1\n",
            "2        6         2\n",
            "3       47         3\n",
            "4       50         4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "=================================================\n",
            "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
            "        [   0,    1,    2,  ..., 3121, 1392, 2873]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use rating as edge features: ale\n",
        "edge_rating = torch.from_numpy((ratings_df['rating'].to_numpy())).to(torch.float)\n",
        "\n",
        "print(edge_rating)\n",
        "print(edge_rating.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-H1d91I3_64",
        "outputId": "54035640-9c46-45c3-83c8-f248eae57ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 4., 4.,  ..., 5., 5., 3.])\n",
            "torch.Size([100836])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "data = HeteroData()\n",
        "# Save node indices:\n",
        "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
        "data[\"movie\"].node_id = torch.arange(len(movies_df))\n",
        "# Add the node features and edge indices:\n",
        "data[\"movie\"].x = movie_feat\n",
        "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie\n",
        "\n",
        "# add edge features -> considerare le feature e' opzinale nel task del prof\n",
        "data[\"user\", \"rates\", \"movie\"].edge_weight = edge_rating\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "data = T.ToUndirected()(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "xasggJwtlfeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Model Implementation\n",
        "- **Objective:** Implement a GNN model suitable for link prediction.\n",
        "- **Tasks:**\n",
        "    1. Define a GNN architecture that can effectively learn to predict the existence of a link between two nodes.\n",
        "    2. Utilize layers and techniques optimized for link prediction, such as message passing and graph pooling, to manage the graph's structure and features."
      ],
      "metadata": {
        "id": "YjhO4tBi2DqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants and Hyperparameters   (FROM Professor)\n",
        "# GCN_LAYERS = 1  # Number of GCN Layers\n",
        "# HIDDEN_DIM = 128  # Number of hidden neurons in each GCN Layer\n",
        "# LEARNING_RATE = 1e-3\n",
        "# WEIGHT_DECAY = 5e-4\n",
        "# MAX_EPOCHS = 4000\n",
        "# BATCH_SIZE = 32\n",
        "# LOG_EVERY_N_STEPS = 10\n",
        "# NUM_NEGATIVE_SAMPLES = 3\n",
        "# RANDOM_STATE = 42\n",
        "\n",
        "GCN_LAYERS = 2  # Number of GCN Layers # modificato ale\n",
        "HIDDEN_DIM = 64  # Number of hidden neurons in each GCN Layer\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 5e-4\n",
        "MAX_EPOCHS = 4000\n",
        "BATCH_SIZE = 128          # modificato ale\n",
        "LOG_EVERY_N_STEPS = 10\n",
        "NUM_NEGATIVE_SAMPLES = 3\n",
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "Yzeck4bdIp-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For this, we first split the set of edges into\n",
        "# training (80%), validation (10%), and testing edges (10%).\n",
        "# Across the training edges, we use 70% of edges for message passing,\n",
        "# and 30% of edges for supervision.\n",
        "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
        "# Negative edges during training will be generated on-the-fly.\n",
        "# We can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=2.0,\n",
        "    add_negative_train_samples=False,\n",
        "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
        "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"),\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)"
      ],
      "metadata": {
        "id": "SMIHbrxol3e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In the first hop, we sample at most 20 neighbors.\n",
        "# In the second hop, we sample at most 10 neighbors.\n",
        "# In addition, during training, we want to sample negative edges on-the-fly with\n",
        "# a ratio of 2:1.\n",
        "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "# Define seed edges:\n",
        "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    weight_attr='edge_weight',\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "QCTtpbBCmEJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    # def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor, edge_weight: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        # return (edge_feat_user * edge_feat_movie * edge_weight[0]).sum(dim=-1) # non funziona perchè sono tutti i pesi.\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
        "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "        self.classifier = Classifier()\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
        "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"movie\"],\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_weight, # per ora non usato, serve?\n",
        "        )\n",
        "        return pred\n",
        "\n",
        "model = Model(hidden_channels=64)"
      ],
      "metadata": {
        "id": "AzFU3vqimMPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Model Training and Evaluation\n",
        "- **Objective:** Train the GNN model in a transductive setting and evaluate its performance on the link prediction task.\n",
        "- **Tasks:**\n",
        "    1. Implement the training loop, applying the model to the entire graph and using techniques suitable for link prediction, including handling of positive and negative edge samples.\n",
        "    2. Utilize appropriate evaluation metrics to assess model performance on predicting the presence or absence of links.\n",
        "    3. Reflect on the model's predictions and the practical implications of its performance within the context of the MovieLens dataset.\n"
      ],
      "metadata": {
        "id": "t1qNqPSr2Mps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOmTe8OEmvvp",
        "outputId": "68e0c42a-42b1-4194-e1df-1bd2a95f8aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:06<00:00, 28.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.4391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:05<00:00, 33.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.3466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:06<00:00, 28.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.3300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:05<00:00, 33.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.3156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:06<00:00, 28.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.2984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "sampled_data = next(iter(val_loader))"
      ],
      "metadata": {
        "id": "hHU8HJnZsLh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        preds.append(model(sampled_data))\n",
        "        ground_truths.append(sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "mTzoIMVMsN9w",
        "outputId": "34c1edea-9016-415d-e661-6100dcba46e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 181.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.9285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Considerations\n",
        "- Discuss the handling of node features and the significance of edge features in the context of link prediction.\n",
        "- Explore various GNN architectures, detailing the rationale behind the chosen model structure and parameters.\n",
        "\n",
        "### Submission Guidelines\n",
        "- Complete the tasks within a Colab notebook.\n",
        "- Comment your code thoroughly to elucidate your implementation choices and methodologies.\n",
        "- Ensure that the notebook can be executed from start to end without errors.\n",
        "- Accompany the notebook with a brief report summarizing your approach, findings, and any encountered challenges."
      ],
      "metadata": {
        "id": "4e1eWw2X2YP9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}